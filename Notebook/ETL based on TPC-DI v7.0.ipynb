{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL based on TPC-DI Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared By:\n",
    "\n",
    "    1. Ahmed El-Sayed Hamdan - 191035\n",
    "    2. Mohamed Ahmed Elkhateeb - 191017\n",
    "    3. Moaaz Youssef Ghonaimy - 191036\n",
    "    4. Maryam Akram Elghalban - 191084"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ETL based on TPC-DI\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = 'python3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the dimensions by reading text, csv or xml files into dataframes then make a transfromation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building StatusType DIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Status from text file using csv function but by passing the delimiter which is |\n",
    "# and the schema has 2 colums. (ST_ID and ST_NAME)\n",
    "\n",
    "statusdf = spark.read.option(\"header\",\"false\")\\\n",
    "    .option(\"delimiter\",\"|\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .schema(\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"ST_ID\",StringType()),\n",
    "                StructField(\"ST_NAME\",StringType())\n",
    "            ]\n",
    "        )\n",
    "    )\\\n",
    "    .csv('Data/StatusType.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|ST_ID|  ST_NAME|\n",
      "+-----+---------+\n",
      "| ACTV|   Active|\n",
      "| CMPT|Completed|\n",
      "| CNCL| Canceled|\n",
      "| PNDG|  Pending|\n",
      "| SBMT|Submitted|\n",
      "+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the reading is done successfully by show the data\n",
    "statusdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from Tax Rate file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data of tax becaseu it will be needed later in customer dimension\n",
    "taxrate = spark.read.option(\"header\",\"false\")\\\n",
    "    .option(\"delimiter\",\"|\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .schema(\n",
    "        StructType(\n",
    "            [\n",
    "                StructField(\"TX_ID\",StringType()),\n",
    "                StructField(\"TX_NAME\",StringType()),\n",
    "                StructField(\"TX_RATE\",FloatType())\n",
    "            ]\n",
    "        )\n",
    "    )\\\n",
    "    .csv('Data/TaxRate.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+\n",
      "|TX_ID|             TX_NAME|TX_RATE|\n",
      "+-----+--------------------+-------+\n",
      "|  US1|U.S. Income Tax B...|   0.15|\n",
      "|  US2|U.S. Income Tax B...|  0.275|\n",
      "|  US3|U.S. Income Tax B...|  0.305|\n",
      "|  US4|U.S. Income Tax B...|  0.355|\n",
      "|  US5|U.S. Income Tax B...|  0.391|\n",
      "+-----+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the reading is done successfully by show the data\n",
    "taxrate.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Date DIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dimension is has a very nice calculated columns week in year, day of week, and quarter in the year\n",
    "# which will facilitae makeing the queries later\n",
    "DimDate = spark.read.option(\"header\",\"false\")\\\n",
    "    .option(\"delimiter\",\"|\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .schema(\n",
    "        StructType(\n",
    "                [\n",
    "                    StructField(\"SK_DateID\",IntegerType()),\n",
    "                    StructField(\"DateValue\",DateType()),                \n",
    "                    StructField(\"DateDesc\",StringType()),\n",
    "                    StructField(\"CalendarYearID\",IntegerType()),\n",
    "                    StructField(\"CalendarYearDesc\",StringType()),\n",
    "                    StructField(\"CalendarQtrID\",IntegerType()),\n",
    "                    StructField(\"CalendarQtrDesc\",StringType()),\n",
    "                    StructField(\"CalendarMonthID\",IntegerType()),\n",
    "                    StructField(\"CalendarMonthDesc\",StringType()),\n",
    "                    StructField('CalendarWeekID',IntegerType()),\n",
    "                    StructField('CalendarWeekDesc',StringType()),\n",
    "                    StructField('DayOfWeekNum',IntegerType()),\n",
    "                    StructField(\"DayOfWeekDesc\",StringType()),\n",
    "                    StructField(\"FiscalYearID\",IntegerType()),\n",
    "                    StructField(\"FiscalYearDesc\",StringType()),\n",
    "                    StructField('FiscalQtrID',IntegerType()),\n",
    "                    StructField('FiscalQtrDesc',StringType()),\n",
    "                    StructField(\"HolidayFlag\",BooleanType())\n",
    "                ]\n",
    "                )\n",
    "            )\\\n",
    "            .csv('Data/Date.txt') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------------+-------------+\n",
      "| DateValue|CalendarYearID|CalendarMonthID|CalendarQtrID|\n",
      "+----------+--------------+---------------+-------------+\n",
      "|1950-01-01|          1950|          19501|        19501|\n",
      "|1950-01-02|          1950|          19501|        19501|\n",
      "|1950-01-03|          1950|          19501|        19501|\n",
      "|1950-01-04|          1950|          19501|        19501|\n",
      "|1950-01-05|          1950|          19501|        19501|\n",
      "+----------+--------------+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the reading is done successfully by show the data\n",
    "DimDate.select('DateValue','CalendarYearID','CalendarMonthID','CalendarQtrID').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Time DIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time dimension\n",
    "Dimtime = spark.read.option(\"header\",\"false\")\\\n",
    "        .option(\"delimiter\",\"|\")\\\n",
    "        .option(\"inferSchema\",\"true\")\\\n",
    "       .schema(\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"SK_TimeID\",IntegerType()),\n",
    "                    StructField(\"TimeValue\",StringType()),\n",
    "                    StructField(\"HourID\",IntegerType()),\n",
    "                    StructField(\"HourDesc\",StringType()),\n",
    "                    StructField(\"MinuteID\",IntegerType()),\n",
    "                    StructField(\"MinuteDesc\",StringType()),\n",
    "                    StructField(\"SecondID\",IntegerType()),\n",
    "                    StructField(\"SecondDesc\",StringType()),\n",
    "                    StructField(\"MarketHoursFlag\",BooleanType()),\n",
    "                    StructField(\"OfficeHoursFlag\",BooleanType())\n",
    "                ]\n",
    "            )\n",
    "        )\\\n",
    "       .csv(\"Data/Time.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------+--------+--------+\n",
      "|SK_TimeID|TimeValue|HourID|MinuteID|SecondID|\n",
      "+---------+---------+------+--------+--------+\n",
      "|        0| 00:00:00|     0|       0|       0|\n",
      "|        1| 00:00:01|     0|       0|       1|\n",
      "|        2| 00:00:02|     0|       0|       2|\n",
      "|        3| 00:00:03|     0|       0|       3|\n",
      "|        4| 00:00:04|     0|       0|       4|\n",
      "+---------+---------+------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the reading is done successfully by show the data\n",
    "Dimtime.select(\"SK_TimeID\", \"TimeValue\", \"HourID\", \"MinuteID\", \"SecondID\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Broker DIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rading data from HR.csv file to get the broker information for later usage in customer dimenstion\n",
    "DimBroker = spark.read\\\n",
    "           .format(\"csv\")\\\n",
    "           .option(\"header\", \"false\")\\\n",
    "           .option(\"inferSchema\",\"true\")\\\n",
    "           .schema(\n",
    "                StructType(\n",
    "                    [\n",
    "                        StructField(\"EmployeeID\",StringType()),\n",
    "                        StructField(\"ManagerID\",StringType()),\n",
    "                        StructField(\"EmployeeFirstName\",StringType()),\n",
    "                        StructField(\"EmployeeLastName\",StringType()),\n",
    "                        StructField(\"EmployeeMI\",StringType()),\n",
    "                        StructField(\"EmployeeJobCode\",StringType()),\n",
    "                        StructField(\"EmployeeBranch\",StringType()),\n",
    "                        StructField(\"EmployeeOffice\",StringType()),\n",
    "                        StructField(\"EmployeePhone\",StringType())\n",
    "                    ]\n",
    "                )\n",
    "            )\\\n",
    "           .load(\"Data/HR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+----------------+\n",
      "|EmployeeID|EmployeeFirstName|EmployeeLastName|\n",
      "+----------+-----------------+----------------+\n",
      "|         0|            Ozkan|         Douglas|\n",
      "|         1|             Suer|         Candice|\n",
      "|         2|        Somisetty|            Jami|\n",
      "|         3|          Mazurek|       Rosalinda|\n",
      "|         4|        Aronovich|        Delphine|\n",
      "+----------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the reading is done successfully by show the data\n",
    "DimBroker.select(\"EmployeeID\", \"EmployeeFirstName\", \"EmployeeLastName\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the count of records before applying the dondition of JOBCODE\n",
    "DimBroker.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the condition of job code which is the brokers are only 314\n",
    "DimBroker = DimBroker.where('EmployeeJobCode == 314')\n",
    "# check the count again to validate that the count after condition is less that the original one\n",
    "DimBroker.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding some UDF to apply then on records of broker dimention\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# here we set IsCurrent column by true  as descriped in documentation\n",
    "#we can use  lit(\"true\") but we choose UDF to be more filixble if we need to apply with condition of check another values\n",
    "\n",
    "def Set_IsCurrent_Col():\n",
    "    return 'true'\n",
    "\n",
    "Set_IsCurrent_Col_UDF = udf(Set_IsCurrent_Col, StringType())\n",
    "DimBroker = DimBroker.withColumn(\"IsCurrent\", Set_IsCurrent_Col_UDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set EndDate column by '9999-12-31' as descriped in documentation\n",
    "def Set_EndDate_Col():\n",
    "    return '9999-12-31'\n",
    "\n",
    "Set_EndDate_Col_UDF = udf(Set_EndDate_Col, StringType())\n",
    "DimBroker = DimBroker.withColumn(\"EndDate\", Set_EndDate_Col_UDF())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set EffectiveDat column by '1950-01-01' which is the erailer date in the date dimension\n",
    "# but it can be alos the current date\n",
    "def Set_EffectiveDate_Col():\n",
    "    return '1950-01-01'\n",
    "\n",
    "Set_EffectiveDate_Col_UDF = udf(Set_EffectiveDate_Col, StringType())\n",
    "DimBroker = DimBroker.withColumn(\"EffectiveDate\", Set_EffectiveDate_Col_UDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set BatchID column by '1' as descriped in documentation becaseu it is historal load and the batch id is 1\n",
    "def Set_BatchID_Col():\n",
    "    return '1'\n",
    "\n",
    "Set_BatchID_Col_UDF = udf(Set_BatchID_Col, StringType())\n",
    "DimBroker = DimBroker.withColumn(\"BatchID\", Set_BatchID_Col_UDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BrokerID: string (nullable = true)\n",
      " |-- ManagerID: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- MiddleInitial: string (nullable = true)\n",
      " |-- Branch: string (nullable = true)\n",
      " |-- Office: string (nullable = true)\n",
      " |-- Phone: string (nullable = true)\n",
      " |-- IsCurrent: string (nullable = true)\n",
      " |-- EndDate: string (nullable = true)\n",
      " |-- EffectiveDate: string (nullable = true)\n",
      " |-- BatchID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare the dimenion with columns that just need renaming from orignal names in csv file as descriped in documenation\n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeeID\",\"BrokerID\")           \n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeeFirstName\",\"FirstName\")\n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeeLastName\",\"LastName\")\n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeeMI\",\"MiddleInitial\")\n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeeBranch\",\"Branch\")\n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeeOffice\",\"Office\")\n",
    "DimBroker = DimBroker.withColumnRenamed(\"EmployeePhone\",\"Phone\")\n",
    "                        \n",
    "DimBroker = DimBroker.drop(\"EmployeeJobCode\")\n",
    "\n",
    "# print schema just to check the columns names and types  \n",
    "DimBroker.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CashTransaction DIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rading data from CashTransaction.txt file to get the CashTransaction information\n",
    "cashtransaction_txt = spark.read.option(\"header\",\"false\")\\\n",
    "        .option(\"delimiter\",\"|\")\\\n",
    "        .option(\"inferSchema\",\"true\")\\\n",
    "        .schema(\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"CT_CA_ID\",IntegerType()),\n",
    "                    StructField(\"CT_DTS\",StringType()),\n",
    "                    StructField(\"CT_AMT\",FloatType()),\n",
    "                    StructField(\"CT_NAME\",StringType())\n",
    "                ]\n",
    "            )\n",
    "        )\\\n",
    "       .csv(\"Data/CashTransaction.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------+--------------------+\n",
      "|CT_CA_ID|             CT_DTS|   CT_AMT|             CT_NAME|\n",
      "+--------+-------------------+---------+--------------------+\n",
      "|       3|2012-07-11 08:09:52|-37215.14|TGDRsaHPherhApDuH...|\n",
      "|      52|2012-07-07 17:08:29| -3178.67|PGwhaPC igAVOmHLJ...|\n",
      "|      55|2012-07-12 17:34:13| -3172.19|uQOUlrpDGHQpeeBGx...|\n",
      "|      61|2012-09-20 03:07:49| -16621.0|VRIGhrJYHmbmNyXtI...|\n",
      "|      28|2012-07-09 07:26:05|  -1315.7|gySbOpZLevgVdfrrw...|\n",
      "+--------+-------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the reading is done successfully by show the data\n",
    "cashtransaction_txt.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+--------+\n",
      "|CT_CA_ID|   CT_AMT|      Date|    Time|\n",
      "+--------+---------+----------+--------+\n",
      "|       3|-37215.14|2012-07-11|08:09:52|\n",
      "|      52| -3178.67|2012-07-07|17:08:29|\n",
      "|      55| -3172.19|2012-07-12|17:34:13|\n",
      "|      61| -16621.0|2012-09-20|03:07:49|\n",
      "|      28|  -1315.7|2012-07-09|07:26:05|\n",
      "+--------+---------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# we need to split the date and time in 2 differnet columns\n",
    "# slit column CT_DTS by Space\n",
    "split_col = split(cashtransaction_txt['CT_DTS'], ' ')\n",
    "# get 1st elemetn as date\n",
    "cashtransaction_txt = cashtransaction_txt.withColumn('Date', split_col.getItem(0))\n",
    "# get second element as time\n",
    "cashtransaction_txt = cashtransaction_txt.withColumn('Time', split_col.getItem(1))\n",
    "# remove unneeded columns\n",
    "cashtransaction_txt = cashtransaction_txt.drop('CT_DTS', 'CT_NAME')\n",
    "\n",
    "# check if it works\n",
    "cashtransaction_txt.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Account and Customer DIM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading XML - NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the XML file of CustomerMgmt.xml to build customer and account dimensions later form it\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# here just check about the New action type\n",
    "def parse_xml(): \n",
    "    results = []\n",
    "    tree = ET.parse('Data/CustomerMgmt.xml')\n",
    "    root = tree.getroot()\n",
    "    for child in root.findall('{http://www.tpc.org/tpc-di}Action'):\n",
    "        #print(child.get('ActionType'))\n",
    "        if ((child.get('ActionType') == \"NEW\")):\n",
    "            rec = []\n",
    "            Customer = child.find('Customer')\n",
    "            rec.append(Customer.get('C_ID'))\n",
    "            rec.append(Customer.get('C_TAX_ID'))\n",
    "            rec.append(Customer.get('C_GNDR'))\n",
    "            rec.append(Customer.get('C_TIER'))\n",
    "            rec.append(Customer.get('C_DOB'))\n",
    "            Name = Customer.find('Name')\n",
    "            C_L_NAME = ''\n",
    "            if Name.find('C_L_NAME').text == None:\n",
    "                rec.append(C_L_NAME)\n",
    "            else:\n",
    "                rec.append(Name.find('C_L_NAME').text)\n",
    "            C_F_NAME = ''\n",
    "            if Name.find('C_F_NAME').text == None:\n",
    "                rec.append(C_F_NAME)\n",
    "            else:\n",
    "                rec.append(Name.find('C_F_NAME').text)\n",
    "            C_M_NAME = ''\n",
    "            if Name.find('C_M_NAME').text == None:\n",
    "                rec.append(C_M_NAME)\n",
    "            else:\n",
    "                rec.append(Name.find('C_M_NAME').text)\n",
    "            Address = Customer.find('Address')\n",
    "            C_ADLINE1 = ''\n",
    "            if Address.find('C_ADLINE1').text == None:\n",
    "                rec.append(C_ADLINE1)\n",
    "            else:\n",
    "                rec.append(Address.find('C_ADLINE1').text)\n",
    "            C_ADLINE2 = ''\n",
    "            if Address.find('C_ADLINE2').text == None:\n",
    "                rec.append(C_ADLINE2)\n",
    "            else:\n",
    "                rec.append(Address.find('C_ADLINE2').text)\n",
    "            rec.append(Address.find('C_ZIPCODE').text)\n",
    "            rec.append(Address.find('C_CITY').text)\n",
    "            rec.append(Address.find('C_STATE_PROV').text)\n",
    "            rec.append(Address.find('C_CTRY').text)\n",
    "            ContactInfo = Customer.find('ContactInfo')\n",
    "            C_PRIM_EMAIL = ''\n",
    "            if ContactInfo.find('C_PRIM_EMAIL').text == None:\n",
    "                rec.append(C_PRIM_EMAIL)\n",
    "            else:\n",
    "                rec.append(ContactInfo.find('C_PRIM_EMAIL').text)\n",
    "            C_ALT_EMAIL = ''\n",
    "            if ContactInfo.find('C_ALT_EMAIL').text == None:\n",
    "                rec.append(C_ALT_EMAIL)\n",
    "            else:\n",
    "                rec.append(ContactInfo.find('C_ALT_EMAIL').text)\n",
    "                \n",
    "            # apply the transformation as the documanation for phone1\n",
    "            #-----------------------------------------------------------\n",
    "            PHONE_1 = ContactInfo.find('C_PHONE_1')\n",
    "            C_PHONE_1 = ''\n",
    "            e_C_PHONE_1 = PHONE_1.find('C_CTRY_CODE')\n",
    "            if PHONE_1.find('C_CTRY_CODE').text == None:\n",
    "                C_PHONE_1 = C_PHONE_1 \n",
    "            else:\n",
    "                C_PHONE_1 = C_PHONE_1 + PHONE_1.find('C_CTRY_CODE').text\n",
    "            e_C_PHONE_1 = PHONE_1.find('C_AREA_CODE')\n",
    "            if PHONE_1.find('C_AREA_CODE').text == None:\n",
    "                C_PHONE_1 = C_PHONE_1 \n",
    "            else:\n",
    "                C_PHONE_1 = C_PHONE_1 + PHONE_1.find('C_AREA_CODE').text\n",
    "            if PHONE_1.find('C_LOCAL').text == None:\n",
    "                C_PHONE_1 = C_PHONE_1 \n",
    "            else:\n",
    "                C_PHONE_1 = C_PHONE_1 + PHONE_1.find('C_LOCAL').text\n",
    "            if PHONE_1.find('C_EXT').text == None:\n",
    "                C_PHONE_1 = C_PHONE_1 \n",
    "            else:\n",
    "                C_PHONE_1 = C_PHONE_1 + PHONE_1.find('C_EXT').text\n",
    "            rec.append(C_PHONE_1)\n",
    "            \n",
    "             # apply the transformation as the documanation for phone2\n",
    "            #-----------------------------------------------------------\n",
    "            PHONE_2 = ContactInfo.find('C_PHONE_2')\n",
    "            C_PHONE_2 = ''\n",
    "            if PHONE_2.find('C_CTRY_CODE').text == None:\n",
    "                C_PHONE_2 = C_PHONE_2\n",
    "            else:    \n",
    "                C_PHONE_2 = C_PHONE_2 + PHONE_2.find('C_CTRY_CODE').text\n",
    "            if PHONE_2.find('C_AREA_CODE').text == None:\n",
    "                C_PHONE_2 = C_PHONE_2\n",
    "            else:\n",
    "                C_PHONE_2 = C_PHONE_2 + PHONE_2.find('C_AREA_CODE').text\n",
    "            if PHONE_2.find('C_LOCAL').text == None:\n",
    "                C_PHONE_2 = C_PHONE_2\n",
    "            else:    \n",
    "                C_PHONE_2 = C_PHONE_2 + PHONE_2.find('C_LOCAL').text\n",
    "            if PHONE_2.find('C_EXT').text == None:\n",
    "                C_PHONE_2 = C_PHONE_2\n",
    "            else:    \n",
    "                C_PHONE_2 = C_PHONE_2 + PHONE_2.find('C_EXT').text\n",
    "            rec.append(C_PHONE_2)\n",
    "            \n",
    "            # apply the transformation as the documanation for phone3\n",
    "            #-----------------------------------------------------------\n",
    "            PHONE_3 = ContactInfo.find('C_PHONE_3')\n",
    "            C_PHONE_3 = ''\n",
    "            if PHONE_3.find('C_CTRY_CODE').text == None:\n",
    "                C_PHONE_3 = C_PHONE_3\n",
    "            else:    \n",
    "                C_PHONE_3 = C_PHONE_3 + PHONE_3.find('C_CTRY_CODE').text\n",
    "            if PHONE_3.find('C_AREA_CODE').text == None:\n",
    "                C_PHONE_3 = C_PHONE_3\n",
    "            else:    \n",
    "                C_PHONE_3 = C_PHONE_3 + PHONE_3.find('C_AREA_CODE').text\n",
    "            if PHONE_3.find('C_LOCAL').text == None:\n",
    "                C_PHONE_3 = C_PHONE_3\n",
    "            else:    \n",
    "                C_PHONE_3 = C_PHONE_3 + PHONE_3.find('C_LOCAL').text\n",
    "            if PHONE_3.find('C_EXT').text == None:\n",
    "                C_PHONE_3 = C_PHONE_3\n",
    "            else:    \n",
    "                C_PHONE_3 = C_PHONE_3 + PHONE_3.find('C_EXT').text\n",
    "            rec.append(C_PHONE_3)    \n",
    "            TaxInfo = Customer.find('TaxInfo')\n",
    "            rec.append(TaxInfo.find('C_LCL_TX_ID').text)\n",
    "            rec.append(TaxInfo.find('C_NAT_TX_ID').text)\n",
    "            Account = Customer.find('Account')\n",
    "            rec.append(Account.get('CA_ID'))\n",
    "            rec.append(Account.get('CA_TAX_ST'))\n",
    "            rec.append(Account.find('CA_B_ID').text)\n",
    "            rec.append(Account.find('CA_NAME').text)\n",
    "            results.append(rec)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = StructType([StructField('C_ID', StringType(), True),\n",
    "                     StructField('C_TAX_ID', StringType(), True),\n",
    "                     StructField('C_GNDR', StringType(), True),\n",
    "                     StructField('C_TIER', StringType(), True),\n",
    "                     StructField('C_DOB', StringType(), True),\n",
    "                     StructField('C_L_NAME', StringType(), True),\n",
    "                     StructField('C_F_NAME', StringType(), True),\n",
    "                     StructField('C_M_NAME', StringType(), True),\n",
    "                     StructField('C_ADLINE1', StringType(), True),\n",
    "                     StructField('C_ADLINE2', StringType(), True),\n",
    "                     StructField('C_ZIPCODE', StringType(), True),\n",
    "                     StructField('C_CITY', StringType(), True),\n",
    "                     StructField('C_STATE_PROV', StringType(), True),\n",
    "                     StructField('C_CTRY', StringType(), True),\n",
    "                     StructField('C_PRIM_EMAIL', StringType(), True),\n",
    "                     StructField('C_ALT_EMAIL', StringType(), True),\n",
    "                     StructField('C_PHONE_1', StringType(), True),\n",
    "                     StructField('C_PHONE_2', StringType(), True),\n",
    "                     StructField('C_PHONE_3', StringType(), True),\n",
    "                     StructField('C_LCL_TX_ID', StringType(), True),\n",
    "                     StructField('C_NAT_TX_ID', StringType(), True),\n",
    "                     StructField('CA_ID', StringType(), True),\n",
    "                     StructField('CA_TAX_ST', StringType(), True),\n",
    "                     StructField('CA_B_ID', StringType(), True),\n",
    "                     StructField('CA_NAME', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from xml and build a datafrmae \n",
    "NEW_df = parse_xml()\n",
    "new_array = spark.sparkContext.parallelize(NEW_df)\n",
    "NEW_df = spark.createDataFrame(NEW_df,new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+----------------+\n",
      "|C_ID|C_F_NAME|C_L_NAME|          C_CITY|\n",
      "+----+--------+--------+----------------+\n",
      "|   0|   Adara| Joannis|        Columbus|\n",
      "|   1|  Jirina| Paperno|       Inglewood|\n",
      "|   2|  Mariam| McBryan|        Berkeley|\n",
      "|   3| Robinia|    Adey|            Hull|\n",
      "|   4|    Lulu| Haubert|Rancho Cucamonga|\n",
      "+----+--------+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure that the data is retrieved successfully\n",
    "NEW_df.select(\"C_ID\", \"C_F_NAME\", \"C_L_NAME\", \"C_CITY\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Customer Dimenstion when ActionType is NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+------+\n",
      "|CustomerID|LastName|FirstName|Gender|\n",
      "+----------+--------+---------+------+\n",
      "|         0| Joannis|    Adara|     F|\n",
      "|         1| Paperno|   Jirina|     F|\n",
      "|         2| McBryan|   Mariam|  null|\n",
      "|         3|    Adey|  Robinia|     B|\n",
      "|         4| Haubert|     Lulu|     m|\n",
      "+----------+--------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# update the names of columsn from original name in xml to custome dimenstion names as documented\n",
    "CustomerDim = NEW_df.withColumnRenamed(\"C_ID\",\"CustomerID\")           \n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_TAX_ID\",\"TaxID\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_L_NAME\",\"LastName\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_F_NAME\",\"FirstName\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_M_NAME\",\"MiddleInitial\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_TIER\",\"Tier\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_DOB\",\"DOB\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_PRIM_EMAIL\",\"Email1\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_ALT_EMAIL\",\"Email2\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_GNDR\",\"Gender\")\n",
    "\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_ADLINE1\",\"AddressLine1\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_ADLINE2\",\"AddressLine2\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_ZIPCODE\",\"PostalCode\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_CITY\",\"City\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_STATE_PROV\",\"State_Prov\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_CTRY\",\"Country\")\n",
    "\n",
    "#Adding status column to be 'ACTV' for all new accounts\n",
    "CustomerDim = CustomerDim.withColumn('Status', lit(\"ACTV\"))\n",
    "\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_PHONE_1\",\"Phone1\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_PHONE_2\",\"Phone2\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"C_PHONE_3\",\"Phone3\")\n",
    "\n",
    "# check if teh data is successfully added to the dimension\n",
    "CustomerDim.select(\"CustomerID\", \"LastName\", \"FirstName\", \"Gender\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+------+---------+----------+-------------+-------+\n",
      "|CustomerID|LastName|FirstName|Gender|IsCurrent|   EndDate|EffectiveDate|BatchID|\n",
      "+----------+--------+---------+------+---------+----------+-------------+-------+\n",
      "|         0| Joannis|    Adara|     F|     true|9999-12-31|   1950-01-01|      1|\n",
      "|         1| Paperno|   Jirina|     F|     true|9999-12-31|   1950-01-01|      1|\n",
      "|         2| McBryan|   Mariam|  null|     true|9999-12-31|   1950-01-01|      1|\n",
      "|         3|    Adey|  Robinia|     B|     true|9999-12-31|   1950-01-01|      1|\n",
      "|         4| Haubert|     Lulu|     m|     true|9999-12-31|   1950-01-01|      1|\n",
      "+----------+--------+---------+------+---------+----------+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add IsCurrent, EndDate, EffectiveDate and BatchID columns using the UDF created before \n",
    "CustomerDim = CustomerDim.withColumn(\"IsCurrent\", Set_IsCurrent_Col_UDF())\n",
    "CustomerDim = CustomerDim.withColumn(\"EndDate\", Set_EndDate_Col_UDF())\n",
    "CustomerDim = CustomerDim.withColumn(\"EffectiveDate\", Set_EffectiveDate_Col_UDF())\n",
    "CustomerDim = CustomerDim.withColumn(\"BatchID\", Set_BatchID_Col_UDF())\n",
    "CustomerDim.select(\"CustomerID\", \"LastName\", \"FirstName\", \"Gender\",\"IsCurrent\", \"EndDate\", \"EffectiveDate\", \"BatchID\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+------+\n",
      "|CustomerID|LastName|FirstName|Gender|\n",
      "+----------+--------+---------+------+\n",
      "|         0| Joannis|    Adara|     F|\n",
      "|         1| Paperno|   Jirina|     F|\n",
      "|         2| McBryan|   Mariam|     U|\n",
      "|         3|    Adey|  Robinia|     U|\n",
      "|         4| Haubert|     Lulu|     M|\n",
      "+----------+--------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gender column transformation is to change any value rather than F or M to U\n",
    "# so first we change m small to be M uppercase, aslo f small to F uppercase\n",
    "# then Transfrom others to U\n",
    "from pyspark.sql.functions import when   \n",
    "CustomerDim = CustomerDim.withColumn('Gender', when(CustomerDim.Gender == 'f', 'F').otherwise(CustomerDim.Gender))\n",
    "CustomerDim = CustomerDim.withColumn('Gender', when(CustomerDim.Gender == 'm', 'M').otherwise(CustomerDim.Gender))\n",
    "CustomerDim = CustomerDim.withColumn('Gender', when(((CustomerDim.Gender != 'F') & (CustomerDim.Gender != 'M')) | (CustomerDim.Gender.isNull()), 'U').otherwise(CustomerDim.Gender))\n",
    "CustomerDim.select(\"CustomerID\", \"LastName\", \"FirstName\", \"Gender\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+--------------------+---------------+\n",
      "|CustomerID|LastName|FirstName| NationalTaxRateDesc|NationalTaxRate|\n",
      "+----------+--------+---------+--------------------+---------------+\n",
      "|         0| Joannis|    Adara|Yukon Income Tax ...|         0.2336|\n",
      "|         1| Paperno|   Jirina|Nunavut Income Ta...|          0.377|\n",
      "|         2| McBryan|   Mariam|Iowa Income Tax f...|         0.0036|\n",
      "|         3|    Adey|  Robinia|Missouri Income T...|          0.015|\n",
      "|         4| Haubert|     Lulu|Manitoba Income T...|          0.394|\n",
      "+----------+--------+---------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a join with tax to get 4 new columns related to taxes\n",
    "# which are NationalTaxRateDesc, NationalTaxRate , LocalTaxRateDesc, LocalTaxRate\n",
    "# by making 2 diffeent joi n with the same table but with different consition \n",
    "# for national the used column is C_NAT_TX_ID\n",
    "# FRO LOCAL the used column is C_LCL_TX_ID\n",
    "CustomerDim = CustomerDim.join(taxrate, CustomerDim.C_NAT_TX_ID == taxrate.TX_ID,how='left')\n",
    "CustomerDim = CustomerDim.drop('C_NAT_TX_ID','TX_ID')\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"TX_NAME\",\"NationalTaxRateDesc\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"TX_RATE\",\"NationalTaxRate\")\n",
    "\n",
    "# chekc if it works!\n",
    "CustomerDim.select(\"CustomerID\", \"LastName\", \"FirstName\", \"NationalTaxRateDesc\", \"NationalTaxRate\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomerDim = CustomerDim.join(taxrate, CustomerDim.C_LCL_TX_ID == taxrate.TX_ID,how='left')\n",
    "CustomerDim = CustomerDim.drop('C_LCL_TX_ID','TX_ID')\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"TX_NAME\",\"LocalTaxRateDesc\")\n",
    "CustomerDim = CustomerDim.withColumnRenamed(\"TX_RATE\",\"LocalTaxRate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+--------------------+---------------+--------------------+------------+\n",
      "|CustomerID|LastName|FirstName| NationalTaxRateDesc|NationalTaxRate|    LocalTaxRateDesc|LocalTaxRate|\n",
      "+----------+--------+---------+--------------------+---------------+--------------------+------------+\n",
      "|         0| Joannis|    Adara|Yukon Income Tax ...|         0.2336|California Tax fo...|      0.0432|\n",
      "|         1| Paperno|   Jirina|Nunavut Income Ta...|          0.377|British Columbia ...|       0.357|\n",
      "|         2| McBryan|   Mariam|Iowa Income Tax f...|         0.0036|New York Income T...|      0.0614|\n",
      "|         3|    Adey|  Robinia|Missouri Income T...|          0.015|Wisconsin Income ...|      0.0675|\n",
      "|         4| Haubert|     Lulu|Manitoba Income T...|          0.394|Ontario Income Ta...|      0.2216|\n",
      "+----------+--------+---------+--------------------+---------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chekc if it works!\n",
    "CustomerDim.select(\"CustomerID\", \"LastName\", \"FirstName\", \"NationalTaxRateDesc\", \"NationalTaxRate\", \"LocalTaxRateDesc\", \"LocalTaxRate\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading XML - ADDACCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this section we read from CustomerMgmt.xml the reset of data but this time with actiontype = ADDACCT\n",
    "def parse_addacct_xml(): \n",
    "    results = []\n",
    "    tree = ET.parse('Data/CustomerMgmt.xml')\n",
    "    root = tree.getroot()\n",
    "    for child in root.findall('{http://www.tpc.org/tpc-di}Action'):\n",
    "        #print(child.get('ActionType'))\n",
    "        if child.get('ActionType') == \"ADDACCT\":\n",
    "            rec = []\n",
    "            Customer = child.find('Customer')\n",
    "            rec.append(Customer.get('C_ID'))\n",
    "            Account = Customer.find('Account')\n",
    "            rec.append(Account.get('CA_ID'))\n",
    "            rec.append(Account.get('CA_TAX_ST'))\n",
    "            rec.append(Account.find('CA_B_ID').text)\n",
    "            rec.append(Account.find('CA_NAME').text)\n",
    "            results.append(rec)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDACCT_schema = StructType([StructField('C_ID', StringType(), True),\n",
    "                     StructField('CA_ID', StringType(), True),\n",
    "                     StructField('CA_TAX_ST', StringType(), True),\n",
    "                     StructField('CA_B_ID', StringType(), True),\n",
    "                     StructField('CA_NAME', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDACCT_df = parse_addacct_xml()\n",
    "ADDACCT_df = spark.sparkContext.parallelize(ADDACCT_df)\n",
    "ADDACCT_df = spark.createDataFrame(ADDACCT_df,ADDACCT_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading XML - CLOSEACCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this section we read from CustomerMgmt.xml the reset of data but this time with actiontype = CLOSEACCT\n",
    "def parse_CLOSEACCT_xml(): \n",
    "    results = []\n",
    "    tree = ET.parse('Data/CustomerMgmt.xml')\n",
    "    root = tree.getroot()\n",
    "    for child in root.findall('{http://www.tpc.org/tpc-di}Action'):\n",
    "        if child.get('ActionType') == \"CLOSEACCT\":\n",
    "            rec = []\n",
    "            Customer = child.find('Customer')\n",
    "            rec.append(Customer.get('C_ID'))\n",
    "            Account = Customer.find('Account')\n",
    "            rec.append(Account.get('CA_ID'))\n",
    "            results.append(rec)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOSEACCT_schema = StructType([StructField('C_ID', StringType(), True),\n",
    "                     StructField('CA_ID', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOSEACCT_df = parse_CLOSEACCT_xml()\n",
    "CLOSEACCT_df = spark.sparkContext.parallelize(CLOSEACCT_df)\n",
    "CLOSEACCT_df = spark.createDataFrame(CLOSEACCT_df,CLOSEACCT_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|C_ID|CA_ID|\n",
      "+----+-----+\n",
      "|  27|   27|\n",
      "|  41|   41|\n",
      "|  55|   55|\n",
      "|  46|   46|\n",
      "|  60|   60|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CLOSEACCT_df.select(\"C_ID\", \"CA_ID\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading XML - INACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this section we read from CustomerMgmt.xml the reset of data but this time with actiontype = INACT\n",
    "def parse_INACT_xml(): \n",
    "    results = []\n",
    "    tree = ET.parse('Data/CustomerMgmt.xml')\n",
    "    root = tree.getroot()\n",
    "    for child in root.findall('{http://www.tpc.org/tpc-di}Action'):\n",
    "        if child.get('ActionType') == \"INACT\":\n",
    "            rec = []\n",
    "            Customer = child.find('Customer')\n",
    "            rec.append(Customer.get('C_ID'))\n",
    "            results.append(rec)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "INACT_schema = StructType([StructField('C_ID', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "INACT_df = parse_INACT_xml()\n",
    "INACT_df = spark.sparkContext.parallelize(INACT_df)\n",
    "INACT_df = spark.createDataFrame(INACT_df,INACT_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|C_ID|\n",
      "+----+\n",
      "|  48|\n",
      "|  41|\n",
      "|  34|\n",
      "|  62|\n",
      "|  55|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INACT_df.select(\"C_ID\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Account Dimenstion when ActionType is NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+---------+--------------------+\n",
      "|AccountID|SK_BrokerID|SK_CustomerID|TaxStatus|         AccountDesc|\n",
      "+---------+-----------+-------------+---------+--------------------+\n",
      "|        0|      17713|            0|        1|CJlmMuFyibKOmKLHI...|\n",
      "|        1|        615|            1|        2|BbxTgVGOlgyrYtVRj...|\n",
      "|        2|       3927|            2|        1|IGzIDNTTRUDKwGaoV...|\n",
      "|        3|       6256|            3|        1|ZHXwHtCcLZqdWhWOP...|\n",
      "|        4|       3412|            4|        1|mzlYZlTIDmOGuKQHO...|\n",
      "+---------+-----------+-------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start building dimension account but with action type = NEW \n",
    "# Select columns needed from custoemr dimension\n",
    "DimAccount = CustomerDim.select(\"CA_ID\",\"CA_B_ID\",\"CustomerID\",\"CA_TAX_ST\",\"CA_NAME\")\n",
    "\n",
    "# set staus to Active as documnetded\n",
    "DimAccount = DimAccount.withColumn('Status', lit(\"ACTV\"))\n",
    "# usign user defined functions to set multiple columsn s happened before in customer dimentsion\n",
    "DimAccount = DimAccount.withColumn(\"IsCurrent\", Set_IsCurrent_Col_UDF())\n",
    "DimAccount = DimAccount.withColumn(\"EndDate\", Set_EndDate_Col_UDF())\n",
    "DimAccount = DimAccount.withColumn(\"EffectiveDate\", Set_EffectiveDate_Col_UDF())\n",
    "DimAccount = DimAccount.withColumn(\"BatchID\", Set_BatchID_Col_UDF())\n",
    "\n",
    "# change names to match the columns names in dimension\n",
    "DimAccount = DimAccount.withColumnRenamed(\"CA_ID\",\"AccountID\")\n",
    "DimAccount = DimAccount.withColumnRenamed(\"CA_B_ID\",\"SK_BrokerID\")\n",
    "DimAccount = DimAccount.withColumnRenamed(\"CustomerID\",\"SK_CustomerID\")\n",
    "DimAccount = DimAccount.withColumnRenamed(\"CA_TAX_ST\",\"TaxStatus\")\n",
    "DimAccount = DimAccount.withColumnRenamed(\"CA_NAME\",\"AccountDesc\")\n",
    "\n",
    "#check if it works!\n",
    "DimAccount.select('AccountID','SK_BrokerID','SK_CustomerID','TaxStatus','AccountDesc').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Fact Cash Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|AccountID|\n",
      "+---------+\n",
      "|     4937|\n",
      "|     2294|\n",
      "|     2069|\n",
      "|     9009|\n",
      "|     4032|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a join with acconunt dimnsion as the documenation\n",
    "cashtransaction = cashtransaction_txt.join(DimAccount,cashtransaction_txt.CT_CA_ID == DimAccount.AccountID)\n",
    "# get distinc values to make sure that the join is done successulyy.\n",
    "cashtransaction.select('AccountID').distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the FACTCASHBALANCES by make a sum for all transaction for user in a day\n",
    "# so we groub by the user and teh ransaction and sum the amount\n",
    "FactCashBalances = cashtransaction.groupBy('Date','CT_CA_ID')\\\n",
    "                                    .agg({\"CT_AMT\":\"sum\"})\\\n",
    "                                    .withColumnRenamed(\"sum(CT_AMT)\",\"Cash\")\\\n",
    "                                    .withColumn(\"BatchID\", Set_BatchID_Col_UDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555761"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FactCashBalances.count()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Required Quries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finaly we strt running the required qureis\n",
    "# but in the beginig we make a join with date dimesion because all queries are dependent on it.\n",
    "cashtransaction = cashtransaction.join(DimDate,FactCashBalances.Date == DimDate.DateValue,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------------+-------------+\n",
      "| DateValue|CalendarYearID|CalendarMonthID|CalendarQtrID|\n",
      "+----------+--------------+---------------+-------------+\n",
      "|2012-10-09|          2012|         201210|        20124|\n",
      "|2012-10-11|          2012|         201210|        20124|\n",
      "|2012-11-05|          2012|         201211|        20124|\n",
      "|2012-09-07|          2012|          20129|        20123|\n",
      "|2012-09-08|          2012|          20129|        20123|\n",
      "+----------+--------------+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure the join is done succeesfulyy\n",
    "cashtransaction.select('DateValue','CalendarYearID', 'CalendarMonthID', 'CalendarQtrID').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|CT_CA_ID|              Cash|\n",
      "+--------+------------------+\n",
      "|     463|-789355.5455322266|\n",
      "|     471| 775647.7464599609|\n",
      "|    1088|-589189.6413574219|\n",
      "|    1238|       -19597.6875|\n",
      "|     243|-771182.8375244141|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first query: Get the sum of transactions per customer for the first quarter of year 1950\n",
    "# but unfortunatly there is no data in theis year so we get the data in 4th quarter in 2012\n",
    "# just we need to replace 20124 by 19501\n",
    "\n",
    "# we get all transaction in the specifed quarter the group by customer to sum them\n",
    "query1 = cashtransaction.where('CalendarQtrID = 20124').groupBy('CT_CA_ID')\\\n",
    "                                    .agg({\"CT_AMT\":\"sum\"})\\\n",
    "                                    .withColumnRenamed(\"sum(CT_AMT)\",\"Cash\")\n",
    "\n",
    "# make sure it works!\n",
    "query1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|CalendarQtrID|     Cash|\n",
      "+-------------+---------+\n",
      "|        20134|998903.25|\n",
      "|        20124| 999889.3|\n",
      "|        20132| 999324.5|\n",
      "|        20163| 998761.1|\n",
      "|        20131| 999928.3|\n",
      "+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#query2 : Get max transaction amount per quarter\n",
    "\n",
    "# we roup by the quarter and get max so the results would be the max transaction amoutn in each quarter\n",
    "query2 = cashtransaction.groupBy('CalendarQtrID')\\\n",
    "                                    .agg({\"CT_AMT\":\"max\"})\\\n",
    "                                    .withColumnRenamed(\"max(CT_AMT)\",\"Cash\")\n",
    "\n",
    "# make sure it works!\n",
    "query2.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+\n",
      "|CalendarWeekID|             Cash|\n",
      "+--------------+-----------------+\n",
      "|         20135|597520.8928222656|\n",
      "|        201252| -36.400146484375|\n",
      "|        201415| 3438.14990234375|\n",
      "|        201249|   -20448.0703125|\n",
      "|         20134|532132.2292480469|\n",
      "+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#query3: For a specific customer ID, get the total amounts of transactions per week.\n",
    "\n",
    "# we choose customer of id =1 as examle for the query\n",
    "# we group by weekID then sum to get all the transaction amount per week fro specific customer.\n",
    "query3 = cashtransaction.where('SK_CustomerID ==1').groupBy('CalendarWeekID')\\\n",
    "                                    .agg({\"CT_AMT\":\"sum\"})\\\n",
    "                                    .withColumnRenamed(\"sum(CT_AMT)\",\"Cash\")\n",
    "\n",
    "# make sure it works!\n",
    "query3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
